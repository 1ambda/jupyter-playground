{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고 문서\n",
    "\n",
    "- https://wikidocs.net/21707\n",
    "- 자연어 처리, 딥러닝 캠프\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 언제 Stemming, Lemmatization 을 활용해야?\n",
    "\n",
    "코퍼스가 부족한 상황에서는 어간이나 표제어가 같은 문장에 대해 같은 샘플로 취급하여 희소성 문제에서 타협을 볼 수 있었음. 딥러닝 이전의 전통적인 머신러닝 방법에서는 단어 및 문장은 불연속적인 존재이므로 희소성 문제에 관한 치명적인 단점이 있었기 때문에, 표제어 추출 및 어간 추출은 괜찮은 방법이었음.\n",
    "\n",
    "그러나 딥러닝을 활용하여 단어 임베딩 (차원 축소) 를 수행할 수 있게 되면서, 희소성 관련 문제는 큰 장애물이 되지 않음. 예를 들어 표제어 추출이나 어간 추출이 다음과 같은 상황에서는 문제가 될 수..\n",
    "\n",
    "- `나는 학교에 가요` 와 `나만 학교에 가요` 를 추출하면, `나 학교 가` 와 같은 값이 나올 수 있고 동일하게 평가될  수 있음\n",
    "\n",
    "따라서 표제어 추출 또는 어간 추출을 하지 않은 상태에서 딥러닝 based 의 모델로 베이스라인을 만들고 이후에 튜닝을 적용하는 것도 하나의 방법."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming vs Lemmatization\n",
    "\n",
    "- https://stackoverflow.com/questions/1787110/what-is-the-true-difference-between-lemmatization-vs-stemming\n",
    "- https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/\n",
    "\n",
    "아주 간략히는, 어간 추출은 단어만 보고 일정한 규칙을 따라 어간을 (Stem) 추출. 반면 표제어어 추출은 맥락을 고려. \n",
    "\n",
    "어간 추출 (Stemming) 과는 달리 표제어 추출은 (Lemmatization) 맥락을 고려하기 때문에 형태만 같다고 동일하게 보지 않을 수 있음. 예를 들어,\n",
    "\n",
    "- `better`, `good` 은 같은 lemma 이나 stemming 에선 뽑히지 않을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 표제어 추출 (Lemmatization)\n",
    "\n",
    "**목적: 단어의 뿌리가 같은지 판단해 단어의 수를 줄일 수 있다.**\n",
    "\n",
    "형태소는 크게 두 가지 종류로 나눌 수 있음\n",
    "- 어간 (stem): 단어의 의미를 담고 있는 핵심 부분\n",
    "- 접사 (affix): 단어에 추가적인 의미를 주는 부분\n",
    "\n",
    "형태학적 파싱은 이 두 가지 구성 요소를 분리하는 작업을 말함. `cats -> cat (어간) + s (접사)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words=[\n",
    "    'policy', \n",
    "    'doing', \n",
    "    'organization', \n",
    "    'have', \n",
    "    'going', \n",
    "    'love', \n",
    "    'lives', \n",
    "    'fly', \n",
    "    'dies', \n",
    "    'watched', \n",
    "    'has', \n",
    "    'starting'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy',\n",
      " 'doing',\n",
      " 'organization',\n",
      " 'have',\n",
      " 'going',\n",
      " 'love',\n",
      " 'life',\n",
      " 'fly',\n",
      " 'dy',\n",
      " 'watched',\n",
      " 'ha',\n",
      " 'starting']\n",
      "have\n"
     ]
    }
   ],
   "source": [
    "pprint([lemmatizer.lemmatize(word) for word in words])\n",
    "\n",
    "# 표제어 추출기는 단어의 정확한 품사를 알아야 정확한 결과를 출력\n",
    "print(lemmatizer.lemmatize('has', 'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어간 추출 (Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "\n",
    "stemmer_porter = PorterStemmer()\n",
    "stemmer_lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['polici',\n",
      " 'do',\n",
      " 'organ',\n",
      " 'have',\n",
      " 'go',\n",
      " 'love',\n",
      " 'live',\n",
      " 'fli',\n",
      " 'die',\n",
      " 'watch',\n",
      " 'ha',\n",
      " 'start']\n",
      "['policy',\n",
      " 'doing',\n",
      " 'org',\n",
      " 'hav',\n",
      " 'going',\n",
      " 'lov',\n",
      " 'liv',\n",
      " 'fly',\n",
      " 'die',\n",
      " 'watch',\n",
      " 'has',\n",
      " 'start']\n"
     ]
    }
   ],
   "source": [
    "# Stemmer 마다 다른 성능\n",
    "pprint([stemmer_porter.stem(word) for word in words])\n",
    "pprint([stemmer_lancaster.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 한국어에서의 어간 추출\n",
    "\n",
    "한국어는 5언 9품사의 구조\n",
    "\n",
    "* 수식언: 관형사, 부사\n",
    "* 관계언: 조사\n",
    "* 독립언: 감탄사\n",
    "* 체언: 명사, 대명사, 수사\n",
    "* 용언: 동사, 형용사\n",
    "\n",
    "이 중 용언에 해당되는 동사 및 형용사는 어간(stem) 과 어미(ending) 로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
